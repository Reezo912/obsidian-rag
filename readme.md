# ğŸ“š Obsidian RAG

> âš ï¸ **Work in Progress** â€” Modular refactor in progress. Breaking changes expected.

Local-first RAG system for chatting with your [Obsidian](https://obsidian.md/) notes. Hybrid search (semantic + BM25), RRF fusion, and LLM-powered answers â€” all running on your machine.

## Features

- ğŸ”’ **100% Local** â€” No cloud dependencies, your notes stay private
- ğŸ” **Hybrid Search** â€” Combines vector similarity (dense) with full-text search (BM25)
- ğŸ”€ **RRF Fusion** â€” Reciprocal Rank Fusion to merge results from both search methods
- ğŸ“ **Source Citations** â€” Every answer references the original note
- âš¡ **GPU Accelerated** â€” Optimized for NVIDIA GPUs

## Tech Stack

| Component | Technology |
|-----------|------------|
| Vector DB | [LanceDB](https://lancedb.github.io/lancedb/) (embedded, serverless) |
| Embeddings | [bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5) (1024 dims) |
| Full-text Search | LanceDB native FTS (BM25) |
| LLM | [RNJ-1 8B](https://www.essential.ai/) via [LM Studio](https://lmstudio.ai/) |
| Chunking | LangChain `MarkdownHeaderTextSplitter` |

## Project Structure

```
obsidian-rag/
â”œâ”€â”€ config.py              # Centralized configuration
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ db.py              # LanceDB wrapper (vector + FTS search)
â”‚   â”œâ”€â”€ chunking.py        # Markdown splitting & chunk ID generation
â”‚   â”œâ”€â”€ embeddings.py      # Embedding model wrapper
â”‚   â”œâ”€â”€ retrieval.py       # Hybrid search + RRF fusion
â”‚   â””â”€â”€ llm.py             # LLM client (LM Studio)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ ingest.py          # Ingestion pipeline (change detection)
â”‚   â””â”€â”€ query.py           # CLI query interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ lancedb/           # Vector database (gitignored)
â””â”€â”€ models/
    â””â”€â”€ embedding/         # Cached model weights (gitignored)
```

## Setup

```bash
# 1. Clone
git clone https://github.com/<your-user>/obsidian-rag.git
cd obsidian-rag

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure
# Edit config.py â€” set VAULT_PATH to your Obsidian vault location

# 4. Start LM Studio with RNJ-1 (or any compatible model)

# 5. Ingest your notes
python scripts/ingest.py

# 6. Query
python scripts/query.py
```

## How It Works

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embed    â”‚â”€â”€â–º Query Vector
â”‚ Query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â”œâ”€â”€â–º Vector Search (Top 50)
    â”‚
    â”œâ”€â”€â–º BM25 Search (Top 50)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RRF      â”‚â”€â”€â–º Combined Top Results
â”‚ Fusion   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM      â”‚â”€â”€â–º Answer with Citations
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Roadmap

- [x] Ingestion pipeline with change detection
- [x] Hybrid search (vector + BM25)
- [x] RRF fusion
- [x] LLM integration
- [ ] Cross-encoder re-ranking
- [ ] Confidence threshold filtering
- [ ] File watcher (auto-sync on changes)
- [ ] FastAPI endpoint
- [ ] Open WebUI integration

## License

MIT
